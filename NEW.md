# AD-DRS Method: Adaptive Merging in Drift-Resistant Space

## 1. Detailed Methodology

**AD-DRS (Adaptive Merging in Drift-Resistant Space)** is a novel Continual Learning method designed to effectively resolve the core **stability-plasticity** trade-off. Our method is built upon a state-of-the-art foundation, introducing a significant enhancement rather than combining disparate ideas.

### 1.1. Foundational Architecture and Rationale for Improvement

We select **"LoRA Subtraction for Drift-Resistant Space" (LoRA-Sub)** as our foundational method for the following reasons:

- [cite_start]**Robust Stability Foundation**: `LoRA-Sub` provides the **Drift-Resistant Space (DRS)**, a proactive and effective mechanism to prevent catastrophic forgetting at its root[cite: 1663].
- [cite_start]**Clear Avenue for Improvement**: Its balancing mechanism, which relies on a rigid **gradient projection**, can overly constrain the model and limit plasticity[cite: 1729].
- [cite_start]**Efficiency**: The DRS creation process does not require storing old data, making the method lightweight[cite: 1727, 2184].

**The research narrative of AD-DRS**: "We inherit the powerful DRS mechanism from `LoRA-Sub` to ensure stability and propose an **adaptive merging** mechanism to replace its rigid balancing method, thereby providing a definitive solution to the stability-plasticity dilemma."

### 1.2. The AD-DRS Pipeline

AD-DRS employs a logical, two-step sequential process for each new task $t$:

#### **Step 1: Plasticity-Search Training in DRS**

The goal of this step is not to produce the final model, but to find a "candidate" model, $\theta_t^{cand}$, that achieves maximum performance on the new task while remaining within a safe region.

- **DRS Inheritance**: The entire training process occurs within the **DRS** generated by `LoRA-Sub`. [cite_start]All gradient updates $g$ are projected into this space ($g_{proj} = P_t P_t^T g$) to avoid conflicts with past knowledge[cite: 1907].
- [cite_start]**Candidate Training**: Starting from the previous task's model, $\theta_{t-1}^*$, we train on the new data $D_t$ using a plasticity-focused loss function (e.g., Cross-Entropy + Triplet Loss)[cite: 1927].
- **Result**: A candidate model $\theta_t^{cand}$ that is an expert on task $t$ and resides within a safe space, though it may not yet be the optimal balance point for all learned tasks.

#### **Step 2: Adaptive Merging to Find the Optimal Balance**

This is the core contribution of AD-DRS, where we find the "sweet spot" between the past and the present.

- **Defining the Merging Endpoints**:
  1.  **Stability Point**: $\theta_{t-1}^*$ (the final model from the previous task, representing perfect stability).
  2.  **Plasticity Point**: $\theta_t^{cand}$ (the candidate model just trained, representing maximum plasticity within the safe space).
- [cite_start]**Applying Bayesian Merging**: We leverage the theory from `BECAME` to find the optimal merging coefficient $\lambda^*$ and compute the final model[cite: 11, 167]:
  $$ \theta*t^* = (1 - \lambda^_) \theta_{t-1}^_ + \lambda^_ \theta_t^{cand} $$
    [cite_start]The coefficient $\lambda^*$ is calculated via a closed-form solution derived from Bayesian principles, using the **Fisher Information Matrix (FIM)** to quantify the trade-off between the benefit of learning the new task (measured by the curvature of the new loss) and the risk of forgetting old ones (measured by the cumulative FIM of past tasks)[cite: 221, 239].

### 1.3. Final Refinements (Optional)

[cite_start]To further optimize performance, techniques such as **Self-Distillation** [cite: 1378] [cite_start]and **Classifier Alignment** [cite: 1365] can be applied to the final merged model, $\theta_t^*$.

---

## 2. To-do List for Implementing AD-DRS from the `LoRA-Sub-DRS` Base Code

This is a detailed guide to upgrade the `LoRA-Sub-DRS` codebase to the full AD-DRS implementation.

### ☐ **Phase 1: Codebase Preparation and Backup**

- [ ] Backup your entire working `LoRA-Sub-DRS` project to a new folder (e.g., `AD-DRS-dev`).
- [ ] Identify the key files for modification:
  - The main training script (e.g., `main.py` or `train.py`).
  - The model definition file (e.g., `model.py` or `vit.py`).
  - Utility files (e.g., `utils.py`).

### ☐ **Phase 2: Modify the Main Training Loop**

- [ ] **Store the Previous State**: In your task loop (`for t in tasks...`), before training on task $t$, add code to save the `state_dict` of the converged model from task $t-1$.
  ```python
  # In main.py, before the epoch loop for task t
  if t > 0:
      theta_t_minus_1_star = {name: p.clone().detach() for name, p in model.named_parameters()}
      # You will also need to save the accumulated Fisher matrix here
      # accumulated_fisher_t_minus_1 = deepcopy(fisher_manager.get_fisher())
  ```
- [ ] **Adjust the Goal**: The purpose of your existing training loop is now to produce the `candidate` model, `theta_t_cand`. No major code changes are needed here, but it's a conceptual shift. The `model` at the end of this loop is your `model_candidate`.
- [ ] **Preserve Core Components**: The logic for creating the **DRS** and **projecting the gradients** should remain unchanged.

### ☐ **Phase 3: Implement the Adaptive Merging Module**

This phase requires the most new code.

- [ ] **Create `fisher_utils.py`**:

  - [ ] Write a `compute_diagonal_fim` function. It takes the `model` and `dataloader` as input and returns a dictionary containing the diagonal of the FIM.

  ```python
  # In fisher_utils.py
  import torch
  import torch.nn.functional as F

  def compute_diagonal_fim(model, dataloader, device):
      fim = {name: torch.zeros_like(p, device=device)
             for name, p in model.named_parameters() if p.requires_grad}

      model.eval()
      for images, labels in dataloader:
          images, labels = images.to(device), labels.to(device)
          model.zero_grad()
          # Use log_softmax to calculate log-likelihood
          outputs = model(images)
          log_probs = F.log_softmax(outputs, dim=1)

          # Get log-likelihood of the correct class
          sampled_log_probs = log_probs.gather(1, labels.view(-1, 1))

          # Compute gradient of log-likelihood
          sampled_log_probs.mean().backward()

          for name, p in model.named_parameters():
              if p.grad is not None:
                  # FIM = E[grad * grad^T]. With diagonal approx., we just need E[grad^2]
                  fim[name] += p.grad.data ** 2

      # Average the FIM over the whole dataset
      for name in fim:
          fim[name] /= len(dataloader)

      return fim
  ```

- [ ] **Create a `FisherManager` Class**: This class will handle storing, accumulating, and retrieving the FIM.

  ```python
  # In fisher_utils.py
  class FisherManager:
      def __init__(self):
          self.accumulated_fisher = {}

      def update_fisher(self, new_fim):
          if not self.accumulated_fisher:
              self.accumulated_fisher = new_fim
          else:
              for name in self.accumulated_fisher:
                  self.accumulated_fisher[name] += new_fim[name]

      def get_fisher(self):
          return self.accumulated_fisher
  ```

- [ ] **Integrate into `main.py`**:

  - [ ] Initialize `fisher_manager = FisherManager()` at the beginning of your script.
  - [ ] After the Plasticity-Search Training loop finishes, add the merging logic.

  ```python
  # In main.py, after the training for task t is complete

  # Get theta_t_cand from the current model state
  theta_t_cand = {name: p.clone().detach() for name, p in model.named_parameters()}

  # For t > 0 (not the first task)
  if t > 0:
      # Compute FIM for the current task with the candidate model
      current_fim = compute_diagonal_fim(model, train_loader_t, device) # This is F_t

      # Get the accumulated FIM from previous tasks
      accumulated_fisher_t_minus_1 = fisher_manager.get_fisher() # This is Λ_{t-1}

      # Calculate lambda_star
      delta_theta = {name: theta_t_cand[name] - theta_t_minus_1_star[name] for name in theta_t_cand}

      # Calculate terms for the lambda* formula
      numerator = sum(torch.sum(delta_theta[n]**2 * current_fim[n]) for n in delta_theta)
      denom_term1 = numerator
      denom_term2 = sum(torch.sum(delta_theta[n]**2 * accumulated_fisher_t_minus_1[n]) for n in delta_theta)

      lambda_star = numerator / (denom_term1 + denom_term2 + 1e-8) # Add epsilon for stability
      lambda_star = torch.clamp(lambda_star, 0.0, 1.0)

      print(f"Task {t+1}: Computed lambda_star = {lambda_star.item()}")

      # Perform the merge to get theta_t_star
      final_theta = {}
      for name in theta_t_cand:
          final_theta[name] = (1 - lambda_star) * theta_t_minus_1_star[name] + lambda_star * theta_t_cand[name]

      # Load the final weights into the model
      model.load_state_dict(final_theta, strict=False)

  # Update the accumulated FIM for the next task
  final_model_fim = compute_diagonal_fim(model, train_loader_t, device)
  fisher_manager.update_fisher(final_model_fim)
  ```

### ☐ **Phase 4: Add Final Refinement Techniques (Optional)**

- [ ] **Classifier Alignment**:
  - [ ] Add logic to store the `mean` and `covariance` of features for each class after every task.
  - [ ] Write a `retrain_classifier(model, all_class_stats)` function that freezes the backbone and retrains the classifier head on features sampled from the stored Gaussian distributions. Call this function after the merging is complete.
- [ ] **Self-Distillation**:
  - [ ] Modify the `forward` pass of your ViT model to return both `class_token` and `patch_tokens`.
  - [ ] Add a `SelfDistillationLoss` term to your total loss function during the Plasticity-Search Training (Phase 2).

### ☐ **Phase 5: Experimentation and Logging**

- [ ] Add logging to record the value of `lambda_star` for each task. This is crucial for analyzing the model's adaptive behavior.
- [ ] Run experiments to compare the performance of the original `LoRA-Sub` with your new `AD-DRS`.
- [ ] (Advanced) Run ablation studies:
  - AD-DRS without merging (i.e., just the PFT step).
  - AD-DRS with a fixed `lambda` (e.g., 0.5) to demonstrate the importance of the adaptive coefficient.
